{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T07:45:47.381548Z",
     "start_time": "2020-07-01T07:45:46.852656Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import math\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T07:45:47.926424Z",
     "start_time": "2020-07-01T07:45:47.475570Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "#train 안불러온다?\n",
    "\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "submission = pd.read_csv(path+'submission.csv')\n",
    "\n",
    "df_copy = test.copy()\n",
    "df_copy.date = pd.to_datetime(df_copy.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T07:45:50.206936Z",
     "start_time": "2020-07-01T07:45:47.928424Z"
    }
   },
   "outputs": [],
   "source": [
    "#날짜 시간 통합\n",
    "df_copy.date = pd.to_datetime(df_copy.date.astype(str) + \" \" + df_copy.time, format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T07:45:50.212938Z",
     "start_time": "2020-07-01T07:45:50.207937Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_noise_by_removing_neg_vals(df_copy):\n",
    "    '''\n",
    "    매출이 음수인 경우는 거래취소이므로 이전결제금액/취소금액을 제외해주기 위한 함수 \n",
    "    '''\n",
    "    df_pos = df_copy[df_copy.amount > 0]\n",
    "    df_neg = df_copy[df_copy.amount < 0]\n",
    "\n",
    "    start = datetime.now()\n",
    "\n",
    "    for nega_i in tqdm(df_neg.to_records()[:]): #df.to_records() : dtype을 보존하면서 numpy로 변경\n",
    "        store_i = nega_i[1]\n",
    "        date_i = nega_i[2]\n",
    "        card_i = nega_i[4]\n",
    "        amt_i = nega_i[5]\n",
    "        row_i = df_pos[df_pos.store_id == store_i] #양수인 것중 store_id가 동일한 경우\n",
    "        row_i = row_i[row_i.card_id == card_i] #그중에서 카드가 동일한 경우\n",
    "        row_i = row_i[row_i.amount >= abs(amt_i)] #음수의 amount가 양수것과 같거다 작은 경우\n",
    "        row_i = row_i[row_i.date <= date_i] #음수의 거래일자와 같거나 적은 경우 \n",
    "        if len(row_i[row_i.amount == abs(amt_i)]) > 0: #거래금액과 음수의 거래금액의 절대값이 동일하다면 \n",
    "            row_i = row_i[row_i.amount == abs(amt_i)] #\n",
    "            matched_row = row_i[row_i.date == max(row_i.date)]#여러개 있다면 마지막 날짜의 데이터를 가져옴 \n",
    "            # df_pos.loc[matched_row.index, 'amount'] = 0\n",
    "            df_pos = df_pos.loc[~df_pos.index.isin(matched_row.index), :] #그부분은 양수쪽에서 삭제\n",
    "        elif len(row_i[row_i.amount > abs(amt_i)]) > 0: #음수보다 크다면\n",
    "            matched_row = row_i[row_i.date == max(row_i.date)]\n",
    "            df_pos.loc[matched_row.index, 'amount'] = matched_row.amount + amt_i #음수인만큼을 더해줌 \n",
    "        # else:\n",
    "        #     pass\n",
    "            # no_match.append(nega_i)\n",
    "    end = datetime.now()\n",
    "    time_took = (end - start).seconds / 60\n",
    "\n",
    "    print(round(time_took, 2))\n",
    "    return df_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T07:51:40.515196Z",
     "start_time": "2020-07-01T07:45:50.213938Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f6649750ac48d2b77f466d42d84eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.83\n"
     ]
    }
   ],
   "source": [
    "df_pos = reduce_noise_by_removing_neg_vals(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.614152Z",
     "start_time": "2020-06-30T07:38:35.611152Z"
    }
   },
   "outputs": [],
   "source": [
    "def adf_test(y):\n",
    "    '''\n",
    "    시계열 데이터의 stationary 검증하기 위해 ADF(Augmented Dickey-Fuller test) 진행\n",
    "    사용되지는 않은듯 \n",
    "    '''\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Augmented Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value ({})'.format(key)] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.622154Z",
     "start_time": "2020-06-30T07:38:35.615152Z"
    }
   },
   "outputs": [],
   "source": [
    "def ts_diagnostics(y, lags=None, title='', filename=''):\n",
    "    '''\n",
    "    Calculate acf, pacf, qq plot and Augmented Dickey Fuller test for a given time series\n",
    "    ?? 또 안썻네?\n",
    "    '''\n",
    "    if not isinstance(y, pd.Series): #y가 시리즈가 아닐때 시리즈로 변환\n",
    "        y = pd.Series(y)\n",
    "\n",
    "    # weekly moving averages (5 day window because of workdays)\n",
    "    rolling_mean = pd.Series.rolling(y, window=2).mean()\n",
    "    rolling_std = pd.Series.rolling(y, window=2).std()\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    layout = (3, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (2, 1))\n",
    "\n",
    "    # time series plot\n",
    "    y.plot(ax=ts_ax)\n",
    "    rolling_mean.plot(ax=ts_ax, color='crimson')\n",
    "    rolling_std.plot(ax=ts_ax, color='darkslateblue')\n",
    "    plt.legend(loc='best')\n",
    "    ts_ax.set_title(title, fontsize=24)\n",
    "\n",
    "    # acf and pacf\n",
    "    plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "    plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n",
    "\n",
    "    # qq plot\n",
    "    sm.qqplot(y, line='s', ax=qq_ax)\n",
    "    qq_ax.set_title('QQ Plot')\n",
    "\n",
    "    # hist plot\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.945636Z",
     "start_time": "2020-06-30T07:38:35.623154Z"
    }
   },
   "outputs": [],
   "source": [
    "#일시별로 묶음\n",
    "df = df_pos.copy()\n",
    "test_groupby_date_store = df.groupby(['date', 'store_id'])['amount', 'holyday'].sum()\n",
    "test_groupby_date_store = test_groupby_date_store.reset_index()\n",
    "\n",
    "test_groupby_date_store = test_groupby_date_store.set_index('date')\n",
    "store_list = test_groupby_date_store.store_id.unique()\n",
    "\n",
    "store_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.950636Z",
     "start_time": "2020-06-30T07:38:35.946635Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimal_params(y):\n",
    "    '''\n",
    "    ARIMA_main 함수에서 사용\n",
    "    파라미터 최적화 함수?\n",
    "    '''\n",
    "    # Define the p, d and q parameters to take any value between 0 and 1\n",
    "\n",
    "    param_dict = {}\n",
    "    for param in pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                            order=param,\n",
    "                                            )\n",
    "            results = mod.fit()\n",
    "            model = ARIMA(y, order=param)\n",
    "            results_ARIMA = model.fit(disp=-1)\n",
    "            results_ARIMA.summary()\n",
    "            param_dict[results.aic] = param\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    min_aic = min(param_dict.keys())\n",
    "    optimal_params = param_dict[min_aic]\n",
    "    return optimal_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.955639Z",
     "start_time": "2020-06-30T07:38:35.951636Z"
    }
   },
   "outputs": [],
   "source": [
    "##?? 뭐야 이부분?\n",
    "sampling_p = 28\n",
    "mean_period = 2 * 3 #14 * 2*3\n",
    "\n",
    "predic_len = math.floor(100 / sampling_p)\n",
    "\n",
    "expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365\n",
    "expected_loss_pct_lending = 1.00\n",
    "optimal_prob = expected_loss_pct_lending / (expected_loss_pct_lending + expected_return_pct_lending)\n",
    "optimal_z_score = st.norm.ppf(optimal_prob) #norm 생성?\n",
    "\n",
    "min_period = 6\n",
    "\n",
    "\n",
    "max_pdq = 2\n",
    "p = d = q = range(0, max_pdq)\n",
    "pdq = list(itertools.product(p, d, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:38:35.961638Z",
     "start_time": "2020-06-30T07:38:35.956637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580957780787686\n",
      "1.7290036387221377\n"
     ]
    }
   ],
   "source": [
    "pdqs = dict()\n",
    "print(optimal_prob)\n",
    "print(optimal_z_score)\n",
    "output_file_name_fmt = 'py_4arima_pos_sep_{optimal_p}-{sampling_period}_no_sales_prob&no mean{mean_period}&min_period {min_period}_pdq{max_pdq}.csv'\n",
    "output_file_name = output_file_name_fmt.format(optimal_p=round(optimal_prob, 4),\n",
    "                                               sampling_period=sampling_p,\n",
    "                                               mean_period=mean_period,\n",
    "                                               min_period=min_period,\n",
    "                                               max_pdq=max_pdq)\n",
    "submission_copy = submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T07:40:31.046695Z",
     "start_time": "2020-06-30T07:40:31.040694Z"
    }
   },
   "outputs": [],
   "source": [
    "def arima_main(input_df, sampling_period_days, fcst_period):\n",
    "    '''\n",
    "    arima모델 메인 \n",
    "    sampling_period_days만큼으로 데이터를 분할하기 위해 나머지만큼은 제외, 가장 과거시점을 제외함\n",
    "    '''\n",
    "    input_df = input_df[len(input_df) % sampling_period_days:].resample(str(sampling_period_days) + 'D').sum() #날짜로 묶음\n",
    "    prob_of_no_sales = len(input_df[(input_df.amount == 0) | (input_df.amount.isna())]) / len(input_df) #0 또는 결측치확인\n",
    "    ts_log = np.log(input_df.amount) #로그변환\n",
    "    ts_log = ts_log[~ts_log.isin([np.nan, np.inf, -np.inf])] #로그변환한 값에서 오류가 있다면 제외\n",
    "\n",
    "    if len(ts_log) < min_period:\n",
    "        return None\n",
    "    if sampling_period_days >= 28:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365 #28기간인경우\n",
    "    elif sampling_period_days >= 14:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 14) / 365  #14기간인경우\n",
    "    else:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365\n",
    "\n",
    "    expected_loss_pct_lending = 1.00\n",
    "    optimal_prob = expected_loss_pct_lending / (expected_loss_pct_lending + expected_return_pct_lending)\n",
    "    optimal_z_score = st.norm.ppf(optimal_prob)\n",
    "\n",
    "    optimal_params = get_optimal_params(ts_log)\n",
    "    pdqs[store_i] = optimal_params\n",
    "\n",
    "    model = ARIMA(ts_log, order=optimal_params) #최적이되는 parms시도\n",
    "    results_ARIMA = model.fit(disp=-1)\n",
    "    fcst = results_ARIMA.forecast(fcst_period) \n",
    "\n",
    "    fcst_means = fcst[0]\n",
    "    fcst_stds = fcst[1]\n",
    "    fcst_i = fcst_means - (fcst_stds * optimal_z_score)\n",
    "    fcst_i = sum(map(lambda x: np.exp(x) if np.exp(x) > 0 else 0, fcst_i))\n",
    "    prediction_i = fcst_i * (1 - prob_of_no_sales)\n",
    "    return prediction_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:38.075865Z",
     "start_time": "2020-06-30T08:26:38.067863Z"
    }
   },
   "outputs": [],
   "source": [
    "sampling_period_days = 14\n",
    "input_df = test_df_daily\n",
    "fcst_period = 7 #결과로 나오는 개수\n",
    "\n",
    "input_df2 = input_df[len(input_df) % sampling_period_days:].resample(str(sampling_period_days) + 'D').sum()\n",
    "prob_of_no_sales = len(input_df2[(input_df2.amount == 0) | (input_df2.amount.isna())]) / len(input_df2)\n",
    "ts_log = np.log(input_df2.amount) #로그변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:38.486957Z",
     "start_time": "2020-06-30T08:26:38.483956Z"
    }
   },
   "outputs": [],
   "source": [
    "if sampling_period_days >= 28:\n",
    "    expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365 #28기간인경우\n",
    "elif sampling_period_days >= 14:\n",
    "    expected_return_pct_lending = 0.13 * (100 + 16 + 14) / 365  #14기간인경우\n",
    "else:\n",
    "    expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:39.120943Z",
     "start_time": "2020-06-30T08:26:38.794026Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_params = get_optimal_params(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:39.124944Z",
     "start_time": "2020-06-30T08:26:39.121943Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ARIMA(ts_log, order=optimal_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:39.453017Z",
     "start_time": "2020-06-30T08:26:39.435013Z"
    }
   },
   "outputs": [],
   "source": [
    "results_ARIMA = model.fit(disp=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:26:39.774088Z",
     "start_time": "2020-06-30T08:26:39.770079Z"
    }
   },
   "outputs": [],
   "source": [
    "fcst = results_ARIMA.forecast(fcst_period) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:28:34.765718Z",
     "start_time": "2020-06-30T08:28:34.762718Z"
    }
   },
   "outputs": [],
   "source": [
    "fcst_means = fcst[0]\n",
    "fcst_stds = fcst[1]\n",
    "fcst_i = fcst_means - (fcst_stds * optimal_z_score)\n",
    "fcst_i = sum(map(lambda x: np.exp(x) if np.exp(x) > 0 else 0, fcst_i))\n",
    "prediction_i = fcst_i * (1 - prob_of_no_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:29:07.444311Z",
     "start_time": "2020-06-30T08:29:07.434553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_no_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-30T07:31:44.679Z"
    }
   },
   "outputs": [],
   "source": [
    "for store_i in store_list[:]:\n",
    "    prediction_i = None\n",
    "    test_df = test_groupby_date_store[test_groupby_date_store.store_id == store_i]\n",
    "    test_df_daily = test_df.resample('D').sum() #날짜단위로 통합 \n",
    "    prediction_i = arima_main(test_df_daily, sampling_period_days=28, fcst_period=3)\n",
    "    # if prediction_i is None:\n",
    "    #     prediction_i = arima_main(test_df_daily, sampling_period_days=21, fcst_period=4)\n",
    "    if prediction_i is None:\n",
    "        prediction_i = arima_main(test_df_daily, sampling_period_days=14, fcst_period=7)\n",
    "    if prediction_i is None:\n",
    "        prediction_i = arima_main(test_df_daily, sampling_period_days=7, fcst_period=12)\n",
    "    if prediction_i is None:\n",
    "        test_df = test_df_daily[len(test_df_daily) % 14:].resample('14D').sum() #???\n",
    "\n",
    "        prob_of_no_sales = len(test_df[(test_df.amount == 0) | (test_df.amount.isna())]) / len(test_df) #0 또는 결측치확인\n",
    "        ts_log = ts_log[~ts_log.isin([np.nan, np.inf, -np.inf])] #log변환한 값에 결측이 있는경우 제외 ts_log???\n",
    "        ts_log_wkly = np.log(test_df.amount)\n",
    "\n",
    "        estimated_amt = np.exp(ts_log_wkly.mean() - ts_log_wkly.std() * optimal_z_score) * (1 - prob_of_no_sales)\n",
    "        prediction_i = estimated_amt * mean_period\n",
    "\n",
    "    submission_copy.loc[submission_copy['store_id'] == store_i, 'total_sales'] = prediction_i\n",
    "\n",
    "submission_copy.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
